{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "43c5ad16",
      "metadata": {
        "id": "43c5ad16"
      },
      "source": [
        "# PPO on PastureEnv\n",
        "This notebook trains Stable-Baselines3 PPO on the custom `PastureEnv`, logs results to CSV, plots metrics, and renders the best policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "741e727f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "741e727f",
        "outputId": "1d70eaa7-37dc-44b7-cd24-de058c45b1db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (1.2.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-2.7.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "!pip  install   stable-baselines3\n",
        "import os, sys, json, time, random, csv\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from custom_env import make_env\n",
        "from eval_utils import evaluate_policy\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo.policies import MlpPolicy as PPOMlpPolicy\n",
        "MODELS_DIR =  Path('models') / 'ppo'\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed3ce7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fed3ce7a",
        "outputId": "65102b78-5c5d-4c22-86de-9c8bc33cfd69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'algo': 'PPO',\n",
              " 'seed': 42,\n",
              " 'env': 'PastureEnv',\n",
              " 'timestamp': '2025-11-24 11:06:34'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "try:\n",
        "    import torch\n",
        "    torch.manual_seed(SEED)\n",
        "except Exception:\n",
        "    torch = None\n",
        "run_meta = {\n",
        "    'algo': 'PPO',\n",
        "    'seed': SEED,\n",
        "    'env': 'PastureEnv',\n",
        "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "with open(MODELS_DIR / 'run_meta.json', 'w') as f: json.dump(run_meta, f, indent=2)\n",
        "run_meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa05911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aa05911",
        "outputId": "613cfee9-2ce8-42b9-eed6-9aeeee6e629c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "TOTAL_TIMESTEPS = int(200_000)\n",
        "EVAL_EPISODES = 5\n",
        "RUN_LIMIT = None \n",
        "grid = {\n",
        "    'learning_rate': [3e-4, 1e-4],\n",
        "    'gamma': [0.99, 0.95],\n",
        "    'n_steps': [1024, 2048],\n",
        "    'batch_size': [64, 128],\n",
        "    'gae_lambda': [0.95, 0.9],\n",
        "    'clip_range': [0.2, 0.1],\n",
        "    'ent_coef': [0.0, 0.01],\n",
        "    'vf_coef': [0.5],\n",
        "}\n",
        "from itertools import product\n",
        "keys = list(grid.keys())\n",
        "combos = [dict(zip(keys, vals)) for vals in product(*[grid[k] for k in keys])]\n",
        "if RUN_LIMIT is not None: combos = combos[:RUN_LIMIT]\n",
        "len(combos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b87932",
      "metadata": {
        "id": "56b87932"
      },
      "outputs": [],
      "source": [
        "\n",
        "from collections import Counter\n",
        "def eval_model(model, episodes=EVAL_EPISODES):\n",
        "    env_fn = lambda: make_env(render_mode=None)\n",
        "    stats = evaluate_policy(env_fn, model, episodes=episodes)\n",
        "    env = env_fn()\n",
        "    counts = Counter()\n",
        "    ep_rewards = []\n",
        "    for _ in range(episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done, trunc = False, False\n",
        "        total = 0.0\n",
        "        while not (done or trunc):\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            counts[int(action)] += 1\n",
        "            obs, r, done, trunc, info = env.step(int(action))\n",
        "            total += r\n",
        "        ep_rewards.append(total)\n",
        "    env.close()\n",
        "    action_counts = [counts.get(i, 0) for i in range(5)]\n",
        "    return stats, action_counts, ep_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f3410b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7f3410b",
        "outputId": "2aa8aff4-22cb-4f05-a564-117738fff071"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Training Loop with Logging and Saving\n",
        "models_dir = MODELS_DIR\n",
        "runs_csv = models_dir / 'ppo_runs.csv'\n",
        "episodes_csv = models_dir / 'ppo_episodes.csv'\n",
        "def ensure_csv_headers(file, headers):\n",
        "    if not file.exists():\n",
        "        with open(file, 'w', newline='') as f:\n",
        "            csv.writer(f).writerow(headers)\n",
        "ensure_csv_headers(runs_csv, ['run_id','timestamp','params','avg_reward','std_reward','avg_length','mean_hunger','mean_thirst','grazing_balance','action_counts','best','time_sec'])\n",
        "ensure_csv_headers(episodes_csv, ['run_id','episode','reward'])\n",
        "best_mean = -1e9\n",
        "best_path = None\n",
        "run_id = 0\n",
        "for params in combos:\n",
        "    run_id += 1\n",
        "    t0 = time.time()\n",
        "    env = make_env(render_mode=None)\n",
        "    model = PPO(\n",
        "        policy=PPOMlpPolicy,\n",
        "        env=env,\n",
        "        verbose=0,\n",
        "        tensorboard_log=str(models_dir / 'tb'),\n",
        "        **params\n",
        "    )\n",
        "    model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
        "    env.close()\n",
        "    stats, action_counts, ep_rewards = eval_model(model, episodes=EVAL_EPISODES)\n",
        "    mean_reward = stats.get('avg_reward', float(np.mean(ep_rewards)))\n",
        "    is_best = ''\n",
        "    if mean_reward > best_mean:\n",
        "        best_mean = mean_reward\n",
        "        best_path = models_dir / 'best_ppo.zip'\n",
        "        model.save(best_path)\n",
        "        is_best = 'yes'\n",
        "    with open(runs_csv, 'a', newline='') as f:\n",
        "        csv.writer(f).writerow([run_id, time.strftime('%Y-%m-%d %H:%M:%S'), str(params), stats.get('avg_reward'), stats.get('std_reward'), stats.get('avg_length'), stats.get('mean_hunger'), stats.get('mean_thirst'), stats.get('grazing_balance_mean'), '|'.join(map(str, action_counts)), is_best, f'{time.time()-t0:.1f}'])\n",
        "    with open(episodes_csv, 'a', newline='') as f:\n",
        "        w = csv.writer(f)\n",
        "        for i, r in enumerate(ep_rewards, 1):\n",
        "            w.writerow([run_id, i, r])\n",
        "best_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4edf0ce",
      "metadata": {
        "id": "a4edf0ce"
      },
      "outputs": [],
      "source": [
        "\n",
        "runs_csv = MODELS_DIR / 'ppo' / 'ppo_runs.csv'\n",
        "episodes_csv = MODELS_DIR / 'ppo' / 'ppo_episodes.csv'\n",
        "if runs_csv.exists():\n",
        "    runs = pd.read_csv(runs_csv)\n",
        "    display(runs.tail())\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(runs['avg_reward'], marker='o')\n",
        "    plt.title('PPO sweep: mean reward per run')\n",
        "    plt.xlabel('run idx')\n",
        "    plt.ylabel('avg_reward')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "if episodes_csv.exists():\n",
        "    eps = pd.read_csv(episodes_csv)\n",
        "    plt.figure(figsize=(7,4))\n",
        "    for rid, df in eps.groupby('run_id'):\n",
        "        plt.plot(df['episode'], df['reward'], alpha=0.5)\n",
        "    plt.title('Per-episode rewards across runs (PPO)')\n",
        "    plt.xlabel('episode')\n",
        "    plt.ylabel('reward')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78795699",
      "metadata": {
        "id": "78795699"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "best_path = MODELS_DIR / 'best_ppo.zip'\n",
        "if Path(best_path).exists():\n",
        "    env = make_env(render_mode=None, render_fps=10)\n",
        "    model = PPO.load(str(best_path), env=env)\n",
        "    obs, _ = env.reset()\n",
        "    done = False; trunc = False; total = 0.0\n",
        "    while not (done or trunc):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, r, done, trunc, info = env.step(int(action))\n",
        "        total += r\n",
        "        env.render()\n",
        "    env.close()\n",
        "    print('Episode reward:', total)\n",
        "else:\n",
        "    print('Best model not found yet. Run training first.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
